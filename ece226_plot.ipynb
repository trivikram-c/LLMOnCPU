{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zNG2FV8ZBvl0"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "from collections import namedtuple\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/Colab Notebooks/ECE226/logs_cpu'\n",
        "model_name_l = ['Llama-3.2-1B-Instruct','Llama-3.2-1B-Instruct-quant','Llama-3.2-3B-Instruct','Llama-3.2-3B-Instruct-quant',\n",
        "         'DeepSeek-R1-Distill-Qwen-1.5B','DeepSeek-R1-Distill-Qwen-1.5B-quant']\n",
        "model_stat = namedtuple('model_stat',['accuracy','avg_Total_generation_time','avg_TTFT','memory_footprint','throughput'])\n",
        "model_info = dict() # {model_name:namedtuple(accuracy,avg_Total_generation_time,TTFT)}\n",
        "for model_name in model_name_l:\n",
        "  with open(path + '/' + 'One-shot-' + model_name + '_Total_generation_time_result.json', 'r') as f:\n",
        "    data = json.load(f)\n",
        "    footprint = data['model loading footprint (GB)']\n",
        "    accuracy = data['accuracy']\n",
        "    total_output_token_count = data['total_output_token_count']\n",
        "    avg_total_generation_time = np.array(data['total_generation_time_l']).mean()\n",
        "    throughput = total_output_token_count/sum(data['total_generation_time_l'])\n",
        "\n",
        "  with open(path + '/' + 'One-shot-' + model_name + '_TTFT_result.json', 'r') as f:\n",
        "    data = json.load(f)\n",
        "    avg_TTFT = np.array(data['TTFT_l']).mean()\n",
        "\n",
        "  model_info[model_name] = model_stat(accuracy,avg_total_generation_time,avg_TTFT,footprint,throughput)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S5_oqj0EB4Z7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name in model_info:\n",
        "  print(f'model_name: {model_name}')\n",
        "  print(f'accuracy: {model_info[model_name].accuracy:.2f}')\n",
        "  print(f'avg_total_generation_time: {model_info[model_name].avg_Total_generation_time:.2f} s')\n",
        "  print(f'avg_TTFT: {model_info[model_name].avg_TTFT:.2f} s')\n",
        "  print(f'memory_footprint: {model_info[model_name].memory_footprint:.2f} GB')\n",
        "  print(f'throughput: {model_info[model_name].throughput:.2f} token/s')\n",
        "  print('###########################')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cz02DrROJkAS",
        "outputId": "55f494bf-4389-4676-c979-1082ad037bbe"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_name: Llama-3.2-1B-Instruct\n",
            "accuracy: 0.23\n",
            "avg_total_generation_time: 19.50 s\n",
            "avg_TTFT: 1.54 s\n",
            "memory_footprint: 4.60 GB\n",
            "throughput: 3.78 token/s\n",
            "###########################\n",
            "model_name: Llama-3.2-1B-Instruct-quant\n",
            "accuracy: 0.19\n",
            "avg_total_generation_time: 3.14 s\n",
            "avg_TTFT: 0.58 s\n",
            "memory_footprint: 1.22 GB\n",
            "throughput: 26.42 token/s\n",
            "###########################\n",
            "model_name: Llama-3.2-3B-Instruct\n",
            "accuracy: 0.53\n",
            "avg_total_generation_time: 145.71 s\n",
            "avg_TTFT: 20.16 s\n",
            "memory_footprint: 11.97 GB\n",
            "throughput: 1.50 token/s\n",
            "###########################\n",
            "model_name: Llama-3.2-3B-Instruct-quant\n",
            "accuracy: 0.42\n",
            "avg_total_generation_time: 16.94 s\n",
            "avg_TTFT: 1.64 s\n",
            "memory_footprint: 3.18 GB\n",
            "throughput: 11.40 token/s\n",
            "###########################\n",
            "model_name: DeepSeek-R1-Distill-Qwen-1.5B\n",
            "accuracy: 0.49\n",
            "avg_total_generation_time: 27.28 s\n",
            "avg_TTFT: 2.25 s\n",
            "memory_footprint: 6.62 GB\n",
            "throughput: 4.57 token/s\n",
            "###########################\n",
            "model_name: DeepSeek-R1-Distill-Qwen-1.5B-quant\n",
            "accuracy: 0.46\n",
            "avg_total_generation_time: 6.22 s\n",
            "avg_TTFT: 0.77 s\n",
            "memory_footprint: 1.76 GB\n",
            "throughput: 21.64 token/s\n",
            "###########################\n"
          ]
        }
      ]
    }
  ]
}